{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d9bcdbd2-3401-41ad-a83f-830e9346e607",
   "metadata": {
    "id": "d9bcdbd2-3401-41ad-a83f-830e9346e607"
   },
   "source": [
    "# **Applied Machine Learning Homework 5: NLP**\n",
    "**Due May 2,2023 (Tuesday) 11:59PM EST**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "EyLMOVXq-bBX",
   "metadata": {
    "id": "EyLMOVXq-bBX"
   },
   "source": [
    "### Instructions\n",
    "\n",
    "1) Please push the .ipynb and .pdf to Github Classroom prior to the deadline, .py file is optional (not needed).<br>\n",
    "2) Please include your Name and UNI below."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "leint4ja8V77",
   "metadata": {
    "id": "leint4ja8V77"
   },
   "source": [
    "##Name:  \n",
    "##UNI: "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70df26be-5638-4b0d-a252-4437eb76aa46",
   "metadata": {
    "id": "70df26be-5638-4b0d-a252-4437eb76aa46"
   },
   "source": [
    "### Natural Language Processing\n",
    "We will train a supervised training model to predict if a tweet has a positive or negative sentiment."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e0d9a19-25ea-4490-b0e8-7909bcdc3d9d",
   "metadata": {
    "id": "2e0d9a19-25ea-4490-b0e8-7909bcdc3d9d"
   },
   "source": [
    "####  **Dataset loading & dev/test splits**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fafa37c4-c8fc-4697-9bbe-11539d710bf7",
   "metadata": {
    "id": "fafa37c4-c8fc-4697-9bbe-11539d710bf7"
   },
   "source": [
    "**1.1) Load the twitter dataset from NLTK library**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f4ce405-237b-42d2-9c81-25ff28deaf4a",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 7559,
     "status": "ok",
     "timestamp": 1680552434830,
     "user": {
      "displayName": "Pooja Srinivasan",
      "userId": "13687370184540140629"
     },
     "user_tz": 240
    },
    "id": "5f4ce405-237b-42d2-9c81-25ff28deaf4a",
    "outputId": "eda237da-0b39-4e12-9a55-54623dddfcb4"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package twitter_samples to /root/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/twitter_samples.zip.\n",
      "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
      "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('twitter_samples')\n",
    "from nltk.corpus import twitter_samples \n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "stop = stopwords.words('english')\n",
    "import pandas as pd\n",
    "import string\n",
    "import re\n",
    "from sklearn.model_selection import train_test_split\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.tokenize import word_tokenize\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import classification_report\n",
    "# Feel free to import any other packages you need"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c41d62ce-3c78-4b6c-9238-111d990d170f",
   "metadata": {
    "id": "c41d62ce-3c78-4b6c-9238-111d990d170f"
   },
   "source": [
    "**1.2) Load the positive & negative tweets**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b92fb408-f72a-4c23-acd8-7c944a52edd3",
   "metadata": {
    "id": "b92fb408-f72a-4c23-acd8-7c944a52edd3"
   },
   "outputs": [],
   "source": [
    "all_positive_tweets = twitter_samples.strings('positive_tweets.json')\n",
    "all_negative_tweets = twitter_samples.strings('negative_tweets.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "Vy1K6hxAjfbi",
   "metadata": {
    "id": "Vy1K6hxAjfbi"
   },
   "source": [
    "**1.3) Make a data frame that has all tweets and their corresponding labels**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6611bdc8",
   "metadata": {
    "id": "6611bdc8"
   },
   "outputs": [],
   "source": [
    "# Your Code Here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "xisDSGVanceN",
   "metadata": {
    "id": "xisDSGVanceN"
   },
   "source": [
    "**1.4) Look at the class distribution of the tweets**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "xv8oL2_gnYra",
   "metadata": {
    "id": "xv8oL2_gnYra"
   },
   "outputs": [],
   "source": [
    "# Your Code Here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12eae071-fd8a-4a46-9958-0525c635fd88",
   "metadata": {
    "id": "12eae071-fd8a-4a46-9958-0525c635fd88"
   },
   "source": [
    "**1.5) Create a development & test split (80/20 ratio):**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f3673db-d7a8-470b-a3d3-f4522cd359b8",
   "metadata": {
    "id": "0f3673db-d7a8-470b-a3d3-f4522cd359b8"
   },
   "outputs": [],
   "source": [
    "# Your Code Here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32b23398-e80e-4624-b89e-c02fabfd3f8d",
   "metadata": {
    "id": "32b23398-e80e-4624-b89e-c02fabfd3f8d"
   },
   "source": [
    "#### **Data preprocessing**\n",
    "We will do some data preprocessing before we tokenize the data. We will remove `#` symbol, hyperlinks, stop words & punctuations from the data. You can use the `re` package in python to find and replace these strings. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f89d9d69-1640-4583-a7b7-7ec04ccf3310",
   "metadata": {
    "id": "f89d9d69-1640-4583-a7b7-7ec04ccf3310"
   },
   "source": [
    "**1.6) Replace the `#` symbol with '' in every tweet**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5db4dd6d-e775-49d3-96e1-57620c042d46",
   "metadata": {
    "id": "5db4dd6d-e775-49d3-96e1-57620c042d46"
   },
   "outputs": [],
   "source": [
    "# Your Code Here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24c4caa8-d71d-46a8-8859-a8e85c56acfe",
   "metadata": {
    "id": "24c4caa8-d71d-46a8-8859-a8e85c56acfe"
   },
   "source": [
    "**1.7) Replace hyperlinks with '' in every tweet**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "I20m5bIZqp9S",
   "metadata": {
    "id": "I20m5bIZqp9S"
   },
   "outputs": [],
   "source": [
    "# Your Code Here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "492ae463-b611-4292-9ad2-b778856bf8bc",
   "metadata": {
    "id": "492ae463-b611-4292-9ad2-b778856bf8bc"
   },
   "source": [
    "**1.8) Remove all stop words**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "HA-1Qs8Vz4mB",
   "metadata": {
    "id": "HA-1Qs8Vz4mB"
   },
   "outputs": [],
   "source": [
    "# Your Code Here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "169bf8ad-f7ba-4e67-a1a0-92fcdd193ab9",
   "metadata": {
    "id": "169bf8ad-f7ba-4e67-a1a0-92fcdd193ab9"
   },
   "source": [
    "**1.9) Remove all punctuations**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fbeaccf",
   "metadata": {
    "id": "5fbeaccf"
   },
   "outputs": [],
   "source": [
    "# Your Code Here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2f1af18-0c07-4ffb-994e-daead4740a53",
   "metadata": {
    "id": "b2f1af18-0c07-4ffb-994e-daead4740a53"
   },
   "source": [
    "**1.10) Apply stemming on the development & test datasets using Porter algorithm**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "gSPLyHbmxC1q",
   "metadata": {
    "id": "gSPLyHbmxC1q"
   },
   "outputs": [],
   "source": [
    "# Your Code Here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "687e23ef-dafd-4183-b2f1-86089e281dd8",
   "metadata": {
    "id": "687e23ef-dafd-4183-b2f1-86089e281dd8"
   },
   "source": [
    "#### **Model training**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c40fa44-01ad-4788-98b9-9c8f0c1252ef",
   "metadata": {
    "id": "0c40fa44-01ad-4788-98b9-9c8f0c1252ef"
   },
   "source": [
    "**1.11) Create bag of words features for each tweet in the development dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d34c009",
   "metadata": {
    "id": "3d34c009"
   },
   "outputs": [],
   "source": [
    "# Your Code Here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4baf65cd-019b-4ff4-b93c-3ca8cfffca8e",
   "metadata": {
    "id": "4baf65cd-019b-4ff4-b93c-3ca8cfffca8e"
   },
   "source": [
    "**1.12) Train a Logistic Regression model on the development dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3433a6b0-408d-462e-9072-3495b21bc97b",
   "metadata": {
    "id": "3433a6b0-408d-462e-9072-3495b21bc97b"
   },
   "outputs": [],
   "source": [
    "# Your Code Here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c16c6f6-7ab2-4d7a-b9dc-098a72381340",
   "metadata": {
    "id": "1c16c6f6-7ab2-4d7a-b9dc-098a72381340"
   },
   "source": [
    "**1.13) Create TF-IDF features for each tweet in the development dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b417843-ffc4-4614-b2ef-964f8ec3e510",
   "metadata": {
    "id": "7b417843-ffc4-4614-b2ef-964f8ec3e510"
   },
   "outputs": [],
   "source": [
    "# Your Code Here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea3c9776-aad9-4eda-b3c2-d9f6b3e52427",
   "metadata": {
    "id": "ea3c9776-aad9-4eda-b3c2-d9f6b3e52427"
   },
   "source": [
    "**1.14) Train the Logistic Regression model on the development dataset with TF-IDF features**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8c7fe8b-61de-4daa-a338-74295a4902ce",
   "metadata": {
    "id": "b8c7fe8b-61de-4daa-a338-74295a4902ce"
   },
   "outputs": [],
   "source": [
    "# Your Code Here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab0129e7-a0ea-473e-9ad1-667b44a13a92",
   "metadata": {
    "id": "ab0129e7-a0ea-473e-9ad1-667b44a13a92"
   },
   "source": [
    "**1.15) Compare the performance of the two models on the test dataset using a classification report and the scores obtained. Explain the difference in results obtained.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "C8NwWxJh33G7",
   "metadata": {
    "id": "C8NwWxJh33G7"
   },
   "outputs": [],
   "source": [
    "# Your Code Here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "uo7vBVNC-_nK",
   "metadata": {
    "id": "uo7vBVNC-_nK"
   },
   "source": [
    "*Explanation here"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
